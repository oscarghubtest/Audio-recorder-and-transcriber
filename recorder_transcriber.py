import pyaudio
import wave
import numpy as np
import os
import time
import threading
import queue
from datetime import datetime
import requests
import json
import random
import azure.cognitiveservices.speech as speechsdk
from google.cloud import speech

last_engine = None  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö mode 'alternate'

# === ‡πÇ‡∏´‡∏•‡∏î config ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå ===
CONFIG_FILE = "recorder_transcriber-config.json"
if not os.path.exists(CONFIG_FILE):
    raise FileNotFoundError("‡πÑ‡∏°‡πà‡∏û‡∏ö recorder_transcriber-config.json")

with open(CONFIG_FILE, "r") as f:
    config = json.load(f)

# === ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Azure Speech API===
SPEECH_KEY = config.get("azure_speech_key","") # Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
SERVICE_REGION = config.get("azure_service_region","") # Location ‡∏´‡∏£‡∏∑‡∏≠ Region ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Resource
LANGUAGE = config.get("azure_language","") # ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á

# === ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Cloud API ===
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = config.get("google_credentials","") # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå Credentials
LANGUAGE_CODE = config.get("google_language_code","") # ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á

# ‡∏î‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå recorder_config.json
FREQUENCY = config.get("frequency","") # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ß‡∏¥‡∏ó‡∏¢‡∏∏‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏°‡∏≤
STATION = config.get("station","") # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏µ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ô‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ç‡∏≤‡∏ô ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
THRESHOLD = config.get("threshold", 500) # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤ ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
RECORD_SECONDS = config.get("record_length",60) # ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏î‡πâ
SILENCE_LIMIT = config.get("silence_limit", 1) # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤ * ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
MIN_DURATION_SEC = config.get("min_duration_sec", 3) # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ * ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
SAVE_FOLDER = config.get("save_folder","audio_files") # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
LOG_FILE = config.get("log_file","system.log") # ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö Log
NUM_WORKERS = config.get("num_workers", 2) # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô worker ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 2 ‡∏´‡∏£‡∏∑‡∏≠ 4)
UPLOAD_URL = config.get("upload_url", "https://catgg.net/ham_radio_recorder_transcriber/upload.php") # URL ‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
TRANSCRIBE_ENGINE = config.get("transcribe_engine", "azure") # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: "azure", "google", "random, "alternate"

# === ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö ===
CHUNK = 1024
RATE = 16000

os.makedirs(SAVE_FOLDER, exist_ok=True)
audio_queue = queue.Queue()

# ‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
def log(msg):
    now = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    print(f"{now} {msg}")
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"{now} {msg}\n")

# ‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á
def record_until_silent():
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16,
                    channels=1,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)

    log("üì° ‡∏£‡∏≠‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á...")
    frames = []
    recording = False
    silence_chunks = 0 # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks ‡∏ó‡∏µ‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å

    if TRANSCRIBE_ENGINE == "google":
        max_record_sec = 59  # ‡∏Ç‡∏≠‡∏á Google Cloud API ‡∏´‡∏≤‡∏Å‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏ß‡πà‡∏≤ 60 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ ‡∏à‡∏∂‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πá‡∏ô 59
    else:
        max_record_sec = RECORD_SECONDS

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
    # ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡πÉ‡∏´‡πâ max_chunks * (CHUNK / RATE) <= max_record_sec
    max_chunks = int(RATE / CHUNK * max_record_sec)

    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        audio_data = np.frombuffer(data, dtype=np.int16)
        amplitude = np.abs(audio_data).mean()

        print(f"üéöÔ∏è Amplitude: {amplitude:.2f}", end='\r')

        if not recording:
            if amplitude > THRESHOLD:
                log("üéôÔ∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏î...")
                recording = True
                frames.append(data)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° chunk ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
                silence_chunks = 0  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏±‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏ö‡∏≤ ‡∏Å‡πá‡∏ß‡∏ô‡∏£‡∏≠‡∏ï‡πà‡∏≠‡πÑ‡∏õ
        else:  # recording is True (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á)
            frames.append(data)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° chunk ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô frames

            if amplitude <= THRESHOLD:  # ‡∏ñ‡πâ‡∏≤ chunk ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏ö‡∏≤
                silence_chunks += 1
            else:  # ‡∏ñ‡πâ‡∏≤ chunk ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á
                silence_chunks = 0  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks ‡∏ó‡∏µ‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏∏‡∏Å chunk
            # 1. ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏û‡∏≠
            stopped_by_silence = silence_chunks > int(RATE / CHUNK * SILENCE_LIMIT)

            # 2. ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
            # ‡πÉ‡∏ä‡πâ >= max_chunks ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô frames ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô max_chunks
            # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô max_chunks * (CHUNK / RATE) ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞ <= max_record_sec
            stopped_by_length = len(frames) >= max_chunks

            if stopped_by_silence or stopped_by_length:
                if stopped_by_length and not stopped_by_silence:
                    log(f"üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏î (‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î {max_record_sec:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")
                elif stopped_by_silence and not stopped_by_length:
                    log(f"üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏î (‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏á‡∏µ‡∏¢‡∏ö {SILENCE_LIMIT} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")
                else:  # ‡∏Å‡∏£‡∏ì‡∏µ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
                    log(f"üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏î (‡∏ñ‡∏∂‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏á‡∏µ‡∏¢‡∏ö)")
                break

    stream.stop_stream()
    stream.close()
    p.terminate()

    duration = len(frames) * CHUNK / RATE
    if duration < MIN_DURATION_SEC:
        log(f"‚õî ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ({duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ) ‚Äî ‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
        return None

    filename = datetime.now().strftime("%Y%m%d_%H%M%S") + ".wav"
    filepath = os.path.join(SAVE_FOLDER, filename)
    wf = wave.open(filepath, 'wb')
    wf.setnchannels(1)
    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()
    log(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á ({duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ) : {filepath}")
    return filepath, duration

# ‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Azure
def transcribe_audio_azure(filepath, duration, engine_used):
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SERVICE_REGION)
    speech_config.speech_recognition_language = LANGUAGE
    audio_config = speechsdk.audio.AudioConfig(filename=filepath)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)

    log(f"üß† ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ Azure: {filepath}")
    result = recognizer.recognize_once()

    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        text = result.text.strip()
        log(f"‚úÖ ‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Azure): {text}")
    elif result.reason == speechsdk.ResultReason.NoMatch:
        text = "[‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ]"
        log("‚ùå Azure: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ")
    else:
        text = "[‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î]"
        log(f"üö´ ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å: {result.reason}")

    with open(filepath.replace(".wav", ".txt"), "w", encoding="utf-8") as f:
        f.write(text)

    upload_audio_and_text(filepath, text, duration, engine_used)

# ‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Google Cloud
def transcribe_audio_google(filepath, duration, engine_used):
    client = speech.SpeechClient()
    log(f"üß† ‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ Google: {filepath}")

    with open(filepath, "rb") as audio_file:
        content = audio_file.read()

    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code=LANGUAGE_CODE,
        audio_channel_count=1,
        enable_automatic_punctuation=True
    )

    response = client.recognize(config=config, audio=audio)

    if not response.results:
        log("‚ùå Google: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ")
        text = "[‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ]"
    else:
        text = response.results[0].alternatives[0].transcript
        log(f"‚úÖ ‡∏ñ‡∏≠‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Google): {text}")

    with open(filepath.replace(".wav", ".txt"), "w", encoding="utf-8") as f:
        f.write(text)

    upload_audio_and_text(filepath, text, duration, engine_used)

# ‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏•‡∏∞‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
def upload_audio_and_text(audio_path, transcript, duration, engine_used):
    source_name = get_source_name(engine_used)

    files = {'audio': open(audio_path, 'rb')}
    data = {
        'transcript': transcript,
        'filename': os.path.basename(audio_path),
        'source': source_name,
        'frequency': FREQUENCY,
        'station': STATION,
        'duration': str(round(duration, 2))
    }
    try:
        res = requests.post(UPLOAD_URL, files=files, data=data)
        if res.status_code == 200:
            log(f"üì§ ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ: filename={data['filename']}, transcript={transcript[:30]}...")
            log("‚òÅÔ∏è ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        else:
            log(f"‚ùå Upload error: {res.status_code}")
    except Exception as e:
        log(f"‚ùå Upload exception: {e}")

def worker(worker_id):
    while True:
        task = audio_queue.get()
        if task:
            filepath, duration = task
            try:
                global last_engine

                engine = TRANSCRIBE_ENGINE

                if TRANSCRIBE_ENGINE == "random":
                    engine = random.choice(["azure", "google"])
                elif TRANSCRIBE_ENGINE == "alternate":
                    if last_engine == "azure":
                        engine = "google"
                    else:
                        engine = "azure"
                    last_engine = engine

                if engine == "azure":
                    log(f"[Worker {worker_id}] üéØ ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö Azure ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                    transcribe_audio_azure(filepath, duration, engine)
                elif engine == "google":
                    log(f"[Worker {worker_id}]  ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö Google ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
                    transcribe_audio_google(filepath, duration, engine)
                else:
                    log("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
            except Exception as e:
                log(f"[Worker {worker_id}]‚ùå ERROR: {e}")
        audio_queue.task_done()

def get_source_name(engine_key):
    return {
        "azure": "Azure AI Speech to Text",
        "google": "Google Cloud Speech-to-Text"
    }.get(engine_key, "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á")

# Loop ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å
if __name__ == "__main__":
    log(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö {get_source_name(TRANSCRIBE_ENGINE)} ‡πÅ‡∏ö‡∏ö real-time (‡πÇ‡∏´‡∏°‡∏î: {TRANSCRIBE_ENGINE})")

    for i in range(NUM_WORKERS):
        threading.Thread(target=worker, args=(i+1,), daemon=True).start()

    while True:
        result = record_until_silent()
        if result:
            filepath, duration = result
            audio_queue.put((filepath, duration))
        time.sleep(0.5)
